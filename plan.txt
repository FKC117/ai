# AI-Powered Analytics System Implementation Guide
# DataFlow Analytics - LangChain + Gemini 1.5 Flash Integration
# Version: 1.0
# Date: January 2025

================================================================================
PHASE 1: ENVIRONMENT SETUP & DEPENDENCIES
================================================================================

STEP 1.1: Verify Current Environment
- ✅ Django project structure is ready
- ✅ LangChain packages are already installed (see requirements.txt)
- ✅ Google Generative AI is installed
- ✅ Environment variables need to be configured

STEP 1.2: Environment Configuration
Create/update .env file in ai/ directory:
SECRET_KEY=your_django_secret_key
GOOGLE_API_KEY=your_gemini_api_key_here
DEBUG=True

STEP 1.3: Verify Dependencies
Current packages in requirements.txt:
- langchain==0.3.27
- langchain-google-genai==2.0.10
- google-generativeai==0.8.5
- pandas==2.1.4
- numpy==1.24.3

================================================================================
PHASE 2: PROJECT STRUCTURE SETUP
================================================================================

STEP 2.1: Create AI Module Structure
Create the following directory structure:
ai/analyticabd/
├── ai/
│ ├── init.py
│ ├── llm_client.py
│ ├── prompt_templates.py
│ ├── conversation_manager.py
│ └── tool_executor.py
├── tools/
│ ├── init.py
│ ├── base_tool.py
│ ├── summary_statistics_tool.py
│ ├── correlation_tool.py
│ ├── regression_tool.py
│ └── tool_registry.py
└── models/
├── init.py
├── chat_models.py
└── conversation_models.py


STEP 2.2: Create Base Files
- Create all __init__.py files
- Create placeholder files for each module
- Set up basic imports and class structures

================================================================================
PHASE 3: CORE AI INFRASTRUCTURE
================================================================================

STEP 3.1: LLM Client Setup (ai/analyticabd/ai/llm_client.py)
```python
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.memory import ConversationBufferMemory

class LLMClient:
    def __init__(self):
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            google_api_key=os.getenv("GOOGLE_API_KEY"),
            temperature=0.7
        )
        self.memory = ConversationBufferMemory()
    
    def chat(self, message, context=None):
        # Implementation for chat functionality
        pass
    
    def interpret_summary_statistics(self, dataset_info, summary_results):
        # Implementation for summary interpretation
        pass
```

STEP 3.2: Prompt Templates (ai/analyticabd/ai/prompt_templates.py)
```python
SUMMARY_INTERPRETATION_PROMPT = """
You are a data analyst expert. Given the following dataset information and summary statistics, 
provide a clear, insightful interpretation that a business user can understand.

Dataset: {dataset_info}
Summary Statistics: {summary_results}

Please provide:
1. Key insights about the data
2. Potential business implications
3. Recommendations for further analysis
4. Any data quality concerns

Write in a conversational, helpful tone.
"""

CHAT_SYSTEM_PROMPT = """
You are an AI data analyst assistant. You help users understand their data and perform analysis.
You have access to various analytical tools and can execute them based on user requests.
Always be helpful, clear, and provide actionable insights.
"""
```

STEP 3.3: Conversation Manager (ai/analyticabd/ai/conversation_manager.py)
```python
class ConversationManager:
    def __init__(self, user_id):
        self.user_id = user_id
        self.conversation_history = []
        self.current_context = {}
    
    def add_message(self, role, content, metadata=None):
        # Add message to conversation history
        pass
    
    def get_context(self):
        # Return conversation context for LLM
        pass
    
    def clear_history(self):
        # Clear conversation history
        pass
```

================================================================================
PHASE 4: TOOL FRAMEWORK IMPLEMENTATION
================================================================================

STEP 4.1: Base Tool Class (ai/analyticabd/tools/base_tool.py)
```python
from abc import ABC, abstractmethod
import pandas as pd

class BaseTool(ABC):
    def __init__(self, dataset_id, user_id):
        self.dataset_id = dataset_id
        self.user_id = user_id
        self.dataset = None
        self.results = None
    
    @abstractmethod
    def execute(self, parameters=None):
        """Execute the tool and return results"""
        pass
    
    @abstractmethod
    def get_description(self):
        """Return tool description for LLM"""
        pass
    
    def load_dataset(self):
        """Load dataset from database"""
        # Implementation to load dataset
        pass
```

STEP 4.2: Summary Statistics Tool (ai/analyticabd/tools/summary_statistics_tool.py)
```python
from .base_tool import BaseTool
import pandas as pd
import numpy as np

class SummaryStatisticsTool(BaseTool):
    def get_description(self):
        return "Generate comprehensive summary statistics for a dataset"
    
    def execute(self, parameters=None):
        # Load dataset
        self.load_dataset()
        
        # Generate summary statistics
        summary = {
            'dataset_overview': self._get_dataset_overview(),
            'variable_summary': self._get_variable_summary(),
            'data_quality': self._get_data_quality(),
            'distribution_insights': self._get_distribution_insights()
        }
        
        self.results = summary
        return summary
    
    def _get_dataset_overview(self):
        # Implementation for dataset overview
        pass
    
    def _get_variable_summary(self):
        # Implementation for variable summary
        pass
    
    def _get_data_quality(self):
        # Implementation for data quality metrics
        pass
    
    def _get_distribution_insights(self):
        # Implementation for distribution insights
        pass
```

STEP 4.3: Tool Registry (ai/analyticabd/tools/tool_registry.py)
```python
class ToolRegistry:
    def __init__(self):
        self.tools = {}
        self._register_default_tools()
    
    def _register_default_tools(self):
        from .summary_statistics_tool import SummaryStatisticsTool
        self.tools['summary_statistics'] = SummaryStatisticsTool
    
    def get_tool(self, tool_name, dataset_id, user_id):
        if tool_name in self.tools:
            return self.tools[tool_name](dataset_id, user_id)
        return None
    
    def list_available_tools(self):
        return list(self.tools.keys())
```

STEP 4.4: Tool Executor (ai/analyticabd/ai/tool_executor.py)
```python
from ..tools.tool_registry import ToolRegistry
from .llm_client import LLMClient

class ToolExecutor:
    def __init__(self):
        self.tool_registry = ToolRegistry()
        self.llm_client = LLMClient()
    
    def execute_tool(self, tool_name, dataset_id, user_id, parameters=None):
        tool = self.tool_registry.get_tool(tool_name, dataset_id, user_id)
        if tool:
            results = tool.execute(parameters)
            return results
        return None
    
    def interpret_results(self, tool_name, results, user_query):
        # Send results to LLM for interpretation
        interpretation = self.llm_client.interpret_results(tool_name, results, user_query)
        return interpretation
```

================================================================================
PHASE 5: DATABASE MODELS
================================================================================

STEP 5.1: Chat Models (ai/analyticabd/models/chat_models.py)
```python
from django.db import models
from django.contrib.auth.models import User

class ChatSession(models.Model):
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    session_id = models.CharField(max_length=255, unique=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    is_active = models.BooleanField(default=True)
    
    class Meta:
        ordering = ['-updated_at']

class ChatMessage(models.Model):
    session = models.ForeignKey(ChatSession, on_delete=models.CASCADE, related_name='messages')
    role = models.CharField(max_length=20)  # 'user', 'assistant', 'system'
    content = models.TextField()
    metadata = models.JSONField(default=dict, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['created_at']

class ToolExecution(models.Model):
    session = models.ForeignKey(ChatSession, on_delete=models.CASCADE, related_name='tool_executions')
    tool_name = models.CharField(max_length=100)
    dataset_id = models.IntegerField()
    parameters = models.JSONField(default=dict, blank=True)
    results = models.JSONField(default=dict, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['-created_at']
```

STEP 5.2: Update Models (ai/analyticabd/models.py)
Add the new models to the existing models.py file and register them in admin.py

================================================================================
PHASE 6: API ENDPOINTS
================================================================================

STEP 6.1: New Views (ai/analyticabd/views.py)
Add the following new view functions:

```python
@login_required
def chat_with_ai(request):
    """Handle AI chat interactions"""
    if request.method == 'POST':
        data = json.loads(request.body)
        message = data.get('message')
        session_id = data.get('session_id')
        
        # Process message and return response
        response = process_chat_message(request.user, message, session_id)
        return JsonResponse(response)

@login_required
def interpret_summary(request):
    """Interpret summary statistics with AI"""
    if request.method == 'POST':
        data = json.loads(request.body)
        dataset_id = data.get('dataset_id')
        
        # Get summary statistics and interpret with AI
        interpretation = interpret_summary_statistics(request.user, dataset_id)
        return JsonResponse({'interpretation': interpretation})

@login_required
def execute_tool(request):
    """Execute a specific analysis tool"""
    if request.method == 'POST':
        data = json.loads(request.body)
        tool_name = data.get('tool_name')
        dataset_id = data.get('dataset_id')
        parameters = data.get('parameters', {})
        
        # Execute tool and return results
        results = execute_analysis_tool(request.user, tool_name, dataset_id, parameters)
        return JsonResponse(results)

@login_required
def get_chat_history(request):
    """Get chat history for current user"""
    sessions = ChatSession.objects.filter(user=request.user, is_active=True)
    history = []
    for session in sessions:
        messages = session.messages.all()[:10]  # Last 10 messages
        history.append({
            'session_id': session.session_id,
            'messages': list(messages.values('role', 'content', 'created_at'))
        })
    return JsonResponse({'history': history})
```

STEP 6.2: URL Configuration (ai/analyticabd/urls.py)
Add the new URL patterns:

```python
# AI Chat URLs
path('api/chat/', views.chat_with_ai, name='chat_with_ai'),
path('api/interpret-summary/', views.interpret_summary, name='interpret_summary'),
path('api/execute-tool/', views.execute_tool, name='execute_tool'),
path('api/chat-history/', views.get_chat_history, name='get_chat_history'),
```

================================================================================
PHASE 7: FRONTEND INTEGRATION
================================================================================

STEP 7.1: Chat Interface (ai/templates/analytics_dashboard.html)
Add the chat interface to the dashboard:

```html
<!-- AI Chat Section -->
<div class="ai-chat-container bg-white border border-border-light rounded-lg p-4 mb-4">
    <div class="flex items-center justify-between mb-4">
        <h3 class="text-lg font-semibold text-primary">AI Assistant</h3>
        <button class="text-text-secondary hover:text-primary" onclick="clearChat()">
            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16"/>
            </svg>
        </button>
    </div>
    
    <div class="chat-messages max-h-64 overflow-y-auto mb-4 space-y-2" id="chat-messages">
        <!-- Messages will be inserted here -->
    </div>
    
    <div class="chat-input flex space-x-2">
        <input type="text" id="chat-input" placeholder="Ask about your data..." 
               class="flex-1 px-3 py-2 border border-border-light rounded-lg focus:outline-none focus:ring-2 focus:ring-primary">
        <button onclick="sendChatMessage()" 
                class="px-4 py-2 bg-primary text-white rounded-lg hover:bg-primary-dark transition-colors">
            Send
        </button>
    </div>
</div>
```

STEP 7.2: "Interpret with AI" Button
Add the button to the summary statistics section:

```html
<!-- Add this button at the bottom of summary statistics content -->
<div class="mt-6 text-center">
    <button onclick="interpretWithAI()" 
            class="px-6 py-3 bg-accent text-white rounded-lg hover:bg-accent-dark transition-colors flex items-center space-x-2 mx-auto">
        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"/>
        </svg>
        <span>Interpret with AI</span>
    </button>
</div>
```

STEP 7.3: JavaScript Functions
Add the following JavaScript functions:

```javascript
// Chat functionality
let currentChatSession = null;

async function sendChatMessage() {
    const input = document.getElementById('chat-input');
    const message = input.value.trim();
    if (!message) return;
    
    // Add user message to chat
    addChatMessage('user', message);
    input.value = '';
    
    // Send to backend
    try {
        const response = await fetch('{% url "chat_with_ai" %}', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value
            },
            body: JSON.stringify({
                message: message,
                session_id: currentChatSession
            })
        });
        
        const data = await response.json();
        
        // Add AI response to chat
        addChatMessage('assistant', data.response);
        
        // Update workspace if tool was executed
        if (data.workspace_update) {
            updateWorkspace(data.workspace_update);
        }
    } catch (error) {
        console.error('Error sending chat message:', error);
        addChatMessage('assistant', 'Sorry, I encountered an error. Please try again.');
    }
}

function addChatMessage(role, content) {
    const messagesContainer = document.getElementById('chat-messages');
    const messageDiv = document.createElement('div');
    messageDiv.className = `p-3 rounded-lg ${role === 'user' ? 'bg-primary text-white ml-8' : 'bg-gray-100 text-text-primary mr-8'}`;
    messageDiv.textContent = content;
    messagesContainer.appendChild(messageDiv);
    messagesContainer.scrollTop = messagesContainer.scrollHeight;
}

async function interpretWithAI() {
    if (currentDatasetIndex === -1) {
        alert('Please select a dataset first.');
        return;
    }
    
    const dataset = datasets[currentDatasetIndex];
    
    try {
        const response = await fetch('{% url "interpret_summary" %}', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value
            },
            body: JSON.stringify({
                dataset_id: dataset.id
            })
        });
        
        const data = await response.json();
        
        // Add interpretation to chat
        addChatMessage('assistant', data.interpretation);
        
    } catch (error) {
        console.error('Error interpreting summary:', error);
        addChatMessage('assistant', 'Sorry, I encountered an error while interpreting your data.');
    }
}

function clearChat() {
    const messagesContainer = document.getElementById('chat-messages');
    messagesContainer.innerHTML = '';
    currentChatSession = null;
}
```

================================================================================
PHASE 8: IMPLEMENTATION ORDER
================================================================================

STEP 8.1: MVP Implementation (Week 1)
1. ✅ Set up environment variables
2. ✅ Create basic LLM client with Gemini 1.5 Flash
3. ✅ Implement Summary Statistics Tool
4. ✅ Add "Interpret with AI" button to summary statistics
5. ✅ Create basic chat interface
6. ✅ Test end-to-end flow

STEP 8.2: Enhanced Features (Week 2)
1. ✅ Add conversation memory
2. ✅ Implement tool registry with multiple tools
3. ✅ Add sophisticated prompt templates
4. ✅ Implement workspace updates from tool results
5. ✅ Add error handling and fallbacks

STEP 8.3: Production Features (Week 3)
1. ✅ Add user authentication to chat sessions
2. ✅ Implement chat history persistence
3. ✅ Add performance optimizations
4. ✅ Create comprehensive error handling
5. ✅ Add API documentation

================================================================================
PHASE 9: TESTING STRATEGY
================================================================================

STEP 9.1: Unit Testing
- Test LLM client functionality
- Test tool execution
- Test conversation management
- Test API endpoints

STEP 9.2: Integration Testing
- Test end-to-end chat flow
- Test tool execution from chat
- Test workspace updates
- Test error scenarios

STEP 9.3: User Testing
- Test with different dataset types
- Test with various user queries
- Test performance with large datasets
- Test user experience flow

================================================================================
PHASE 10: FUTURE ENHANCEMENTS
================================================================================

STEP 10.1: Additional Tools
- Correlation analysis tool
- Regression analysis tool
- Time series analysis tool
- Clustering analysis tool

STEP 10.2: N8N Integration Preparation
- Standardize API responses
- Add webhook endpoints
- Create automation triggers
- Document integration patterns

STEP 10.3: Messaging App Integration
- Prepare for WhatsApp/Telegram integration
- Create message format standards
- Implement user session management
- Add mobile-optimized responses

================================================================================
NOTES & CONSIDERATIONS
================================================================================

1. API Key Security: Ensure GOOGLE_API_KEY is properly secured
2. Rate Limiting: Implement rate limiting for API calls
3. Error Handling: Comprehensive error handling for all scenarios
4. Performance: Optimize for large datasets and concurrent users
5. User Experience: Ensure smooth, responsive interface
6. Scalability: Design for future growth and additional tools

================================================================================
TROUBLESHOOTING GUIDE
================================================================================

Common Issues:
1. API Key not found - Check .env file and environment variables
2. LangChain import errors - Verify package installation
3. Database migration errors - Run makemigrations and migrate
4. Frontend JavaScript errors - Check browser console for details
5. Tool execution failures - Verify dataset loading and tool parameters

================================================================================
SUCCESS METRICS
================================================================================

1. User Engagement: Chat interactions per session
2. Tool Usage: Frequency of tool executions
3. User Satisfaction: Feedback on AI interpretations
4. Performance: Response times for chat and tool execution
5. Error Rates: Successful vs failed operations

================================================================================
This implementation guide provides a comprehensive roadmap for building an AI-powered analytics system with LangChain and Gemini 1.5 Flash. Follow the phases in order for best results.
================================================================================